# ğŸ“š GuÃ­a Completa de Entrenamiento - Clasificador de Residuos

DocumentaciÃ³n completa para entrenar modelos de clasificaciÃ³n de residuos usando **PyTorch** o **TensorFlow**.

---

## ğŸ¯ Tabla de Contenidos

1. [Prerequisitos](#-prerequisitos)
2. [PreparaciÃ³n de Datos](#-preparaciÃ³n-de-datos)
3. [Entrenamiento con PyTorch](#-entrenamiento-con-pytorch)
4. [Entrenamiento con TensorFlow](#-entrenamiento-con-tensorflow)
5. [Estructura de Datos Esperada](#-estructura-de-datos-esperada)
6. [Utilidades de Entrenamiento](#-utilidades-de-entrenamiento)
7. [Troubleshooting](#-troubleshooting)

---

## âœ… Prerequisitos

### Dependencias Requeridas

SegÃºn el framework que uses, instala las dependencias:

#### **Para PyTorch (GPU Recomendado)**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install opencv-python-headless numpy pillow tqdm
```

**Verificar instalaciÃ³n:**
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'GPU: {torch.cuda.is_available()}')"
```

#### **Para TensorFlow (CPU o GPU)**
```bash
pip install tensorflow[and-cuda]
pip install opencv-python-headless numpy pillow
```

**Verificar instalaciÃ³n:**
```bash
python -c "import tensorflow as tf; print(f'TensorFlow: {tf.__version__}'); print(f'GPUs: {len(tf.config.list_physical_devices(\"GPU\"))}')"
```

### Hardware Recomendado

| Framework | CPU MÃ­nimo | GPU Recomendada | VRAM MÃ­nima |
|-----------|-----------|-----------------|------------|
| **PyTorch** | Intel i5 / AMD Ryzen 5 | NVIDIA RTX 3060 | 6GB |
| **TensorFlow** | Intel i7 / AMD Ryzen 7 | NVIDIA RTX 3080 | 8GB |

---

## ğŸ–¼ï¸ PreparaciÃ³n de Datos

### OpciÃ³n 1: Capturar ImÃ¡genes con tu CÃ¡mara

```bash
python training/capture_dataset.py
```

**Controles:**
- **ESPACIO** - Capturar imagen
- **â†‘ / â†“** - Ajustar brillo
- **D** - Mostrar/ocultar informaciÃ³n
- **Q** - Salir y siguiente clase

**Pasos:**
1. Selecciona clase (ej: "plastico")
2. Captura ~100-150 imÃ¡genes por clase
3. VarÃ­a Ã¡ngulos, distancia y rotaciÃ³n
4. Repite para todas las clases

**Ejemplo:**
```bash
# Capturar imÃ¡genes de plÃ¡stico
python training/capture_dataset.py
# Luego selecciona "plastico" y captura imÃ¡genes

# Luego papel
# Luego vidrio
# Etc...
```

### OpciÃ³n 2: Usar Dataset Existente

Coloca tus imÃ¡genes en `training/data/` con estructura:
```
training/data/
â”œâ”€â”€ plastico/
â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ papel/
â”œâ”€â”€ vidrio/
â”œâ”€â”€ metal/
â”œâ”€â”€ carton/
â””â”€â”€ trash/
```

### Validar Dataset

```bash
python training/analyze_dataset.py
```

**Salida esperada:**
```
ğŸ“Š CONTEO DE IMÃGENES
- plastico................. 145 imÃ¡genes
- papel.................... 142 imÃ¡genes
- vidrio................... 148 imÃ¡genes
- metal.................... 146 imÃ¡genes
- carton................... 143 imÃ¡genes
- trash.................... 141 imÃ¡genes
------
TOTAL...................... 865 imÃ¡genes

âš–ï¸ BALANCE DE CLASES
âœ“ Dataset estÃ¡ bien balanceado
âœ“ No hay imÃ¡genes corruptas
```

**Recomendaciones:**
- âœ… MÃ­nimo 100 imÃ¡genes por clase
- âœ… MÃ­nimo 500 imÃ¡genes totales
- âœ… ImÃ¡genes bien balanceadas
- âœ… VariaciÃ³n en Ã¡ngulos y condiciones de luz

---

## âš¡ Entrenamiento con PyTorch

### ConfiguraciÃ³n RÃ¡pida

```bash
cd training
python train_waste_classifier_pytorch.py --data-dir data --epochs 10
```

### Opciones Disponibles

```bash
python train_waste_classifier_pytorch.py \
  --data-dir data \           # Directorio de datos (default: data)
  --epochs 10 \               # NÃºmero de Ã©pocas (default: 10)
  --batch-size 32 \           # Batch size (default: 32)
  --lr 0.001 \                # Learning rate (default: 0.001)
  --output mobilenetv2_waste_pytorch_best.pth \  # Nombre salida
  --unfreeze 50 \             # Capas a descongelar (default: 50)
  --num-workers 4             # Workers para data loading (default: 0)
```

### Proceso de Entrenamiento (2 Fases)

```
FASE 1: Entrenar custom head (30-50% de Ã©pocas)
â”œâ”€â”€ Modelo base (MobileNetV2) CONGELADO
â”œâ”€â”€ Solo entrena custom head (cabezal personalizado)
â”œâ”€â”€ Learning rate: 1e-3 (alto)
â””â”€â”€ Aproximadamente 3-5 minutos

FASE 2: Fine-tune del modelo base (50-70% de Ã©pocas)
â”œâ”€â”€ Descongelan Ãºltimas 50 capas del modelo base
â”œâ”€â”€ Todo el modelo se entrena
â”œâ”€â”€ Learning rate: 1e-4 (bajo)
â””â”€â”€ Aproximadamente 10-15 minutos
```

### Ejemplo Completo

```bash
# 1. Ir a carpeta training
cd training

# 2. Capturar/preparar datos
python capture_dataset.py
# O colocar datos en data/

# 3. Validar dataset
python analyze_dataset.py

# 4. Entrenar modelo
python train_waste_classifier_pytorch.py \
  --data-dir data \
  --epochs 20 \
  --batch-size 32 \
  --lr 0.001

# 5. Resultado final
# âœ… Modelo guardado: models/mobilenetv2_waste_pytorch.pth
# ğŸ¯ Accuracy: 91.88%
```

### Monitoreo en Tiempo Real

Durante el entrenamiento verÃ¡s:
```
Epoch [1/20] Train Loss: 0.8234, Acc: 72.45% | Val Loss: 0.5123, Acc: 85.32%
Epoch [2/20] Train Loss: 0.5123, Acc: 82.15% | Val Loss: 0.3456, Acc: 89.12%
Epoch [3/20] Train Loss: 0.3456, Acc: 89.67% | Val Loss: 0.2123, Acc: 91.88%
...
âœ… Entrenamiento completado
ğŸ“ Modelo guardado: models/mobilenetv2_waste_pytorch_best.pth
ğŸ¯ Accuracy: 91.88%
```

### ParÃ¡metros Recomendados por Escenario

#### Dataset PequeÃ±o (< 500 imÃ¡genes)
```bash
python train_waste_classifier_pytorch.py \
  --epochs 5 \
  --batch-size 16 \
  --lr 0.0005
```

#### Dataset Mediano (500-1000 imÃ¡genes)
```bash
python train_waste_classifier_pytorch.py \
  --epochs 10 \
  --batch-size 32 \
  --lr 0.001
```

#### Dataset Grande (> 1000 imÃ¡genes)
```bash
python train_waste_classifier_pytorch.py \
  --epochs 20 \
  --batch-size 64 \
  --lr 0.001 \
  --unfreeze 100
```

### Tiempo de Entrenamiento Estimado

| GPU | Batch=32 | Batch=64 |
|-----|----------|----------|
| NVIDIA GTX 1660 SUPER | 15-20 min | 12-18 min |
| NVIDIA RTX 3060 | 8-12 min | 6-10 min |
| NVIDIA RTX 4090 | 3-5 min | 2-4 min |
| CPU (Intel i7) | 45-60 min | 60-90 min |

---

## ğŸ”§ Entrenamiento con TensorFlow

### ConfiguraciÃ³n RÃ¡pida

```bash
cd training
python train_waste_classifier.py --data-dir data --epochs 10
```

### Opciones Disponibles

```bash
python train_waste_classifier.py \
  --data-dir data \           # Directorio de datos (default: data)
  --epochs 10 \               # NÃºmero de Ã©pocas (default: 10)
  --batch-size 32 \           # Batch size (default: 32)
  --lr 0.001 \                # Learning rate (default: 0.001)
  --output mobilenetv2_waste.h5 \  # Nombre salida
  --unfreeze 50               # Capas a descongelar (default: 50)
```

### Proceso de Entrenamiento (2 Fases)

```
FASE 1: Entrenar custom head (30-50% de Ã©pocas)
â”œâ”€â”€ Modelo base (MobileNetV2) CONGELADO
â”œâ”€â”€ Solo entrena custom head
â”œâ”€â”€ Learning rate: 1e-3 (alto)
â””â”€â”€ Early stopping: sÃ­ (detiene si no mejora)

FASE 2: Fine-tune del modelo base (50-70% de Ã©pocas)
â”œâ”€â”€ Descongelan Ãºltimas 50 capas
â”œâ”€â”€ Todo el modelo se entrena
â”œâ”€â”€ Learning rate: 1e-4 (bajo)
â””â”€â”€ Aproximadamente 15-20 minutos
```

### Ejemplo Completo

```bash
# 1. Ir a carpeta training
cd training

# 2. Capturar/preparar datos
python capture_dataset.py
# O colocar datos en data/

# 3. Validar dataset
python analyze_dataset.py

# 4. Entrenar modelo
python train_waste_classifier.py \
  --data-dir data \
  --epochs 20 \
  --batch-size 32 \
  --lr 0.001

# 5. Resultado final
# âœ… Modelo guardado: models/mobilenetv2_waste_best.h5
# ğŸ¯ Accuracy: 89.45%
```

### Monitoreo en Tiempo Real

Durante el entrenamiento verÃ¡s:
```
Epoch 1/20
125/125 [==============================] - 45s 360ms/step - loss: 0.8234 - accuracy: 0.7245 - val_loss: 0.5123 - val_accuracy: 0.8532
Epoch 2/20
125/125 [==============================] - 42s 336ms/step - loss: 0.5123 - accuracy: 0.8215 - val_loss: 0.3456 - val_accuracy: 0.8912
...
âœ… Entrenamiento completado
ğŸ“ Modelo guardado: models/mobilenetv2_waste_best.h5
ğŸ¯ Accuracy: 89.45%
```

### ParÃ¡metros Recomendados por Escenario

#### Dataset PequeÃ±o (< 500 imÃ¡genes)
```bash
python train_waste_classifier.py \
  --epochs 5 \
  --batch-size 16 \
  --lr 0.0005
```

#### Dataset Mediano (500-1000 imÃ¡genes)
```bash
python train_waste_classifier.py \
  --epochs 10 \
  --batch-size 32 \
  --lr 0.001
```

#### Dataset Grande (> 1000 imÃ¡genes)
```bash
python train_waste_classifier.py \
  --epochs 20 \
  --batch-size 64 \
  --lr 0.001 \
  --unfreeze 100
```

### Tiempo de Entrenamiento Estimado

| GPU | Batch=32 | Batch=64 |
|-----|----------|----------|
| NVIDIA RTX 3080 | 20-25 min | 15-20 min |
| NVIDIA A100 | 8-10 min | 5-8 min |
| TPU v4 | 3-5 min | 2-3 min |
| CPU (Intel i7) | 60-90 min | 90-120 min |

---

## ğŸ“ Estructura de Datos Esperada

### Estructura de Carpetas Requerida

```
training/
â”œâ”€â”€ capture_dataset.py           # Script para capturar imÃ¡genes
â”œâ”€â”€ analyze_dataset.py           # AnÃ¡lisis de dataset
â”œâ”€â”€ train_waste_classifier_pytorch.py    # Entrenador PyTorch
â”œâ”€â”€ train_waste_classifier.py            # Entrenador TensorFlow
â”œâ”€â”€ check_gpu.py                 # Verificar GPU
â”‚
â”œâ”€â”€ data/                        # ğŸ“ DATOS (creas tÃº)
â”‚   â”œâ”€â”€ plastico/
â”‚   â”‚   â”œâ”€â”€ 000001.jpg
â”‚   â”‚   â”œâ”€â”€ 000002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ papel/
â”‚   â”‚   â”œâ”€â”€ 000001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ vidrio/
â”‚   â”œâ”€â”€ metal/
â”‚   â”œâ”€â”€ carton/
â”‚   â””â”€â”€ trash/
â”‚
â””â”€â”€ models/                      # ğŸ“ MODELOS (se crean aquÃ­)
    â”œâ”€â”€ mobilenetv2_waste_pytorch_best.pth
    â”œâ”€â”€ mobilenetv2_waste.h5
    â””â”€â”€ ...
```

### Nombres de Clases Soportadas

El script detecta automÃ¡ticamente las clases desde los directorios:

```
âœ… Soportadas automÃ¡ticamente:
  - plastico
  - papel
  - vidrio
  - metal
  - carton
  - organico
  - trash
  - (cualquier nombre de directorio)

âŒ NO usar espacios ni caracteres especiales en nombres
```

---

## ğŸ› ï¸ Utilidades de Entrenamiento

### 1. Verificar GPU

```bash
python training/check_gpu.py
```

**Salida esperada (PyTorch disponible):**
```
âœ“ 1 GPU(s) disponible(s)
  - /physical_device:GPU:0 (NVIDIA GeForce GTX 1660 SUPER)
âœ“ GPU detectada para TensorFlow
```

### 2. Analizar Dataset

```bash
python training/analyze_dataset.py --data-dir data
```

**InformaciÃ³n que proporciona:**
- Cantidad de imÃ¡genes por clase
- TamaÃ±os de imÃ¡genes
- ImÃ¡genes corruptas (si las hay)
- Balance de clases
- Recomendaciones

### 3. Capturar ImÃ¡genes

```bash
python training/capture_dataset.py --output-dir data
```

**Ejemplo interactivo:**
```
CAPTURANDO: PLASTICO
Directorio: data/plastico
ImÃ¡genes existentes: 0
Target: 100 imÃ¡genes

CONTROLES:
  ESPACIO  - Capturar imagen
  â†‘â†“       - Ajustar brillo
  D        - Mostrar/ocultar info
  Q        - Salir

âœ“ CÃ¡mara iniciada
Capturadas: 1/100 | Brillo: 0
Capturadas: 2/100 | Brillo: 0
...
âœ… Completado: 100/100 imÃ¡genes
```

---

## ğŸ“Š ComparaciÃ³n de Frameworks

| Aspecto | PyTorch | TensorFlow |
|--------|---------|-----------|
| **Velocidad (GPU)** | ğŸŸ¢ RÃ¡pido | ğŸŸ¡ Medio |
| **Velocidad (CPU)** | ğŸŸ¡ Medio | ğŸ”´ Lento |
| **Curva de aprendizaje** | ğŸŸ¢ FÃ¡cil | ğŸŸ¡ Medio |
| **GPU Support Windows** | ğŸŸ¢ Excelente | ğŸ”´ Limitado |
| **GPU Support Linux** | ğŸŸ¢ Excelente | ğŸŸ¢ Excelente |
| **TamaÃ±o modelo** | ğŸŸ¢ PequeÃ±o (~13MB) | ğŸŸ¡ Medio (~30MB) |
| **Memoria RAM** | ğŸŸ¢ Poco | ğŸŸ¡ MÃ¡s |
| **Facilidad debugar** | ğŸŸ¢ Muy fÃ¡cil | ğŸŸ¡ Medio |
| **ProducciÃ³n** | ğŸŸ¢ Excelente | ğŸŸ¢ Excelente |

**RecomendaciÃ³n:**
- ğŸ¯ **Windows + GPU** â†’ PyTorch â­
- ğŸ¯ **Linux + GPU** â†’ TensorFlow o PyTorch
- ğŸ¯ **CPU only** â†’ PyTorch (mÃ¡s rÃ¡pido)

---

## ğŸ” Resultados y EvaluaciÃ³n

### MÃ©tricas Esperadas

**DespuÃ©s de entrenamiento completo (20 Ã©pocas):**

| Framework | Accuracy | Loss | Tiempo |
|-----------|----------|------|--------|
| PyTorch | 88-93% | 0.15-0.25 | 15-20 min |
| TensorFlow | 85-91% | 0.18-0.30 | 20-25 min |

### InterpretaciÃ³n de Resultados

```
âœ… EXCELENTE (>90% accuracy)
â”œâ”€â”€ Modelo listo para producciÃ³n
â”œâ”€â”€ MÃ­nimo overfitting detectado
â””â”€â”€ Usar para aplicaciones crÃ­ticas

âš ï¸ BUENO (85-90% accuracy)
â”œâ”€â”€ Aceptable para mayorÃ­a de casos
â”œâ”€â”€ Posible overfitting moderado
â””â”€â”€ Considera recolectar mÃ¡s datos si es crÃ­tico

âš ï¸ REGULAR (80-85% accuracy)
â”œâ”€â”€ Necesita mejora
â”œâ”€â”€ Probable bajo balance de datos
â””â”€â”€ Captura mÃ¡s imÃ¡genes por clase

ğŸ”´ MALO (<80% accuracy)
â”œâ”€â”€ Revisar calidad de datos
â”œâ”€â”€ Dataset muy pequeÃ±o
â”œâ”€â”€ Aumentar Ã©pocas de entrenamiento
â””â”€â”€ Usar diferentes parÃ¡metros
```

---

## ğŸš€ IntegraciÃ³n en la AplicaciÃ³n

DespuÃ©s de entrenar, integra el modelo en FastAPI:

### 1. Actualizar ConfiguraciÃ³n

Edita `.env`:
```env
# Para PyTorch
MODEL_PATH=models/mobilenetv2_waste_pytorch_best.pth
MODEL_FRAMEWORK=pytorch

# O para TensorFlow
MODEL_PATH=models/mobilenetv2_waste.h5
MODEL_FRAMEWORK=tensorflow
```

### 2. Iniciar API

```bash
cd .. && python run.py
```

### 3. Probar PredicciÃ³n

```bash
# En otra terminal
curl -X POST "http://localhost:8000/predict" \
  -F "file=@test_image.jpg"
```

---

## ğŸ› Troubleshooting

### PyTorch - Errores Comunes

#### Error: "CUDA out of memory"
```bash
# Reducir batch size
python train_waste_classifier_pytorch.py --batch-size 16

# O usar CPU
export CUDA_VISIBLE_DEVICES=''  # Windows: set CUDA_VISIBLE_DEVICES=
python train_waste_classifier_pytorch.py
```

#### Error: "No CUDA devices available"
```bash
# Verificar instalaciÃ³n CUDA
python -c "import torch; print(torch.cuda.is_available())"

# Reinstalar PyTorch con CUDA
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

#### Error: "No module named torch"
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### TensorFlow - Errores Comunes

#### Error: "CUDA out of memory"
```bash
# Reduce batch size
python train_waste_classifier.py --batch-size 16

# O limitador de memoria GPU
export TF_FORCE_GPU_ALLOW_GROWTH=true
python train_waste_classifier.py
```

#### Error: "Could not load dynamic library 'nvcuda.dll'"
Instala NVIDIA CUDA Toolkit desde: https://developer.nvidia.com/cuda-downloads

#### Error: "No module named tensorflow"
```bash
pip install tensorflow[and-cuda]
```

### Problemas de Datos

#### Error: "No subdirectories of classes"
```bash
# Estructura incorrecta. Debe ser:
training/data/
â”œâ”€â”€ plastico/
â”œâ”€â”€ papel/
â””â”€â”€ ...

# NO:
training/data/
â””â”€â”€ todas_mis_fotos.jpg
```

#### Advertencia: "Dataset estÃ¡ desbalanceado"
```bash
# Captura mÃ¡s imÃ¡genes de clases minoritarias
python capture_dataset.py
# Luego selecciona la clase con menos imÃ¡genes
```

### Lentitud General

#### El entrenamiento es muy lento (>2 min/Ã©poca)
```bash
# 1. Verificar GPU
python training/check_gpu.py

# 2. Aumentar workers si usas PyTorch
python train_waste_classifier_pytorch.py --num-workers 4

# 3. Aumentar batch size (si memoria lo permite)
python train_waste_classifier_pytorch.py --batch-size 64

# 4. Usar CPU en lugar de GPU (para comparar)
export CUDA_VISIBLE_DEVICES=''
python train_waste_classifier_pytorch.py
```

---

## ğŸ“ˆ Mejoras Avanzadas

### Aumentar Accuracy Existente

1. **Capturar mÃ¡s datos**
   ```bash
   python capture_dataset.py
   # +200 imÃ¡genes adicionales
   ```

2. **Data Augmentation mÃ¡s agresivo**
   - Editar `train_waste_classifier_pytorch.py` lÃ­nea ~155
   - Aumentar `RandomRotation`, `RandomAffine`, etc.

3. **Fine-tuning mÃ¡s agresivo**
   ```bash
   python train_waste_classifier_pytorch.py \
     --epochs 30 \
     --unfreeze 100 \
     --lr 0.0005
   ```

4. **Usar modelo mÃ¡s grande**
   - Editar script para usar `ResNet50` en lugar de `MobileNetV2`

### Transfer Learning con Datos Externos

Si tienes un dataset pequeÃ±o, usar un modelo preentrenado mejor:

```python
# En train_waste_classifier_pytorch.py
# Cambiar lÃ­nea ~50
base_model = models.resnet50(pretrained=True)  # MÃ¡s preciso
# base_model = models.mobilenet_v2(pretrained=True)  # MÃ¡s rÃ¡pido
```

---

## âœ… Checklist Final

Antes de usar el modelo en producciÃ³n:

- [ ] Dataset tiene 100+ imÃ¡genes por clase
- [ ] Dataset estÃ¡ bien balanceado
- [ ] Accuracy > 85% en validaciÃ³n
- [ ] Loss < 0.5
- [ ] Modelo guardado correctamente
- [ ] Modelo cargado correctamente en app
- [ ] API responde correctamente
- [ ] Test de predicciÃ³n exitoso

---

## ğŸ“ Soporte

Para problemas:

1. Revisa logs en `logs/` si existen
2. Ejecuta `python training/check_gpu.py`
3. Ejecuta `python training/analyze_dataset.py`
4. Prueba con dataset pequeÃ±o primero
5. Revisa versiones de dependencias

```bash
# Ver versiones instaladas
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import tensorflow; print(f'TensorFlow: {tensorflow.__version__}')"
python -c "import cv2; print(f'OpenCV: {cv2.__version__}')"
```

---

**Ãšltima actualizaciÃ³n:** Diciembre 2024  
**VersiÃ³n:** 1.0
